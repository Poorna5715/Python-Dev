# -*- coding: utf-8 -*-
"""Analysis on Playstore Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IfGCOjNBL15vX0-d-eMkJYLtws5fU9cw

##Analysis On Playstore Data

Let's take a look at the data, which consists of two files:

* Playstore data.csv: Contains all the details of the applications on Google
   Play. - Each app has details like category, rating, size, and more. There's also a dataset with customer reviews. Explore and analyze this data to find out what makes apps successful and engaging.
* user_reviews.csv: Contains 100 reviews for each app, most helpful first. The
  text in each review has been pre-processed and attributed with three new features: Sentiment (Positive, Negative or Neutral), Sentiment Polarity and Sentiment Subjectivity. Before jumping into the data's provided, let me first explain you about the EDA analysis.
"""

Github_link='/content/Play Store Data.csv'

"""##Objectives Outliers

Distribution of App Ratings: What is the distribution of ratings across different apps?

Average Rating by Category: What is the average rating of apps in each category?

Number of Apps by Content Rating: How many apps fall under each content rating category?

Average App Size by Category: What is the average size of apps in different categories?

App Count by Category: How many apps are there in each category?

Correlation between Reviews and Rating: Is there a correlation between the number of reviews and the rating of apps?

Distribution of App Prices: What is the distribution of app prices?

Price Comparison by Category: How do app prices compare across different categories?

Content Rating by Category: What is the distribution of content ratings within each app category?

Genres with Highest Ratings: Which genres have the highest average ratings?

Installs Distribution: What is the distribution of the number of installs for apps?

Rating vs. Price: How does the price of an app affect its rating?

Top Rated Free vs. Paid Apps: How do the top-rated free apps compare to the top-rated paid apps?

Number of Reviews by Category: How many reviews do apps in each category receive on average?

Average Rating by Content Rating: What is the average rating of apps for each content rating category?

##Exploratory Data Analysis(EDA)
  Exploratory Data Analysis (EDA) is a key step in any Data Analysis or Data Science project. It helps you dive into your data to spot patterns, outliers (unusual data points), and form initial ideas about what the data is telling you. By using summary statistics and a range of visualizations, you can get a clear and attractive overview of the data’s main features. This process guides you on how to best work with your data to answer your key questions.

  Here are the key steps in the Exploratory Data Analysis (EDA) process, condensed into five points:
  1. Understand the Data: Study the dataset and its attributes to grasp their
     meaning and relevance to the problem.
  2.Develop Hypotheses: Form initial hypotheses based on the attributes to  
    guide your analysis
  3.Perform Analysis:
      Univariate Analysis: Examine single attributes to summarize and find patterns.
      Bivariate and Multivariate Analysis: Explore relationships between two or more attributes.
  4.Clean the Data: Handle missing data, outliers, and categorical        variables to prepare the dataset for analysis.
  5.Test Hypotheses: Verify if the data supports your hypotheses and meets the requirements for further analysis.

##  Explore Playstore Apps Data

##Import Useful Liabraries
"""

#Import ueseful liabraries
import pandas as pd # Data Manipulation Liabrary
import numpy as np # linear algebra
import matplotlib.pyplot as plt #Data Visulization Tool
import seaborn as sns
from datetime import datetime

#load csv_file
file_path = '/content/Play Store Data.csv'
playstore_df=pd.read_csv(file_path)

playstore_df.head(10)

"""##Get the Null blanks and Dtype"""

playstore_df.info()

#finding the number of rows and columns in Dataset
print(playstore_df.columns)
rows=playstore_df.shape[0]
columns=playstore_df.shape[1]
print(f"The number of rows {rows} and columns {columns} in the dataset")

playstore_df.describe()

"""##Cleaning of Data

##Handling the Null values in the Playstore Data
"""

summary=pd.DataFrame({
    'datatypes':playstore_df.dtypes,
    'not null values':playstore_df.count(),
    'null_values':playstore_df.isnull().sum(),
    'unique_count':playstore_df.nunique()
})
summary

"""##Findings
   The number of null values in are:
        The "Rating" column has 1,474 missing values❓, which is about 13.60% of the data. The "Type" column has 1 missing value, making up 0.01% of the data. The "Content Rating" column also has 1 missing value, which is 0.01% of the data. The "Current Ver" column has 8 missing values, which is 0.07% of the data. Lastly, the "Android Ver" column has 3 missing values, accounting for 0.03% of the data.

## 1.)Null values in the Android Ver column
"""

#The Android Ver column containing Null vaules
playstore_df[playstore_df['Android Ver'].isnull()]

# Finding the different values the 'Android Ver' column takes
playstore_df["Android Ver"].value_counts()

#Finding the shape of dataset
playstore_df.shape

"""## Drop three rows in Android ver column"""

#Removing Nan values in Android ver column
playstore_df=playstore_df[playstore_df['Android Ver'].notna()]
playstore_df.shape

"""## we are successfully removed null values in Android  Ver column

## 2.) Current Ver: There are total 8 Null values in these column
"""

#Finding rows containing the null values in current ver column
playstore_df[playstore_df['Current Ver'].isnull()]

#finding different values the current ver column takes
playstore_df['Current Ver'].value_counts()

"""##since there are only 8 rows with Nan values in current ver column so we have to clean it from current ver column in the dataset"""

#removing Null values from current ver column
playstore_df =playstore_df[playstore_df['Current Ver'].notna()]
# Shape of the updated dataframe
playstore_df.shape

"""## 3.)Rating: These column contain 1470 Nan values

"""

#The rows containing Nan values in Rating column
playstore_df[playstore_df['Rating'].isnull()]

"""##Find the mean median in rating column excluding the Nan values"""

mean_rating=round(playstore_df[~playstore_df['Rating'].isnull()]['Rating'].mean(),4)
median_rating=playstore_df[~playstore_df['Rating'].isnull()]['Rating'].median()
[mean_rating,median_rating]

"""##Visualization of Distribution of Rating using"""

fig, ax = plt.subplots(2,1,figsize=(12,7))
sns.histplot(playstore_df['Rating'],color='firebrick',ax=ax[0])
sns.boxplot(x='Rating',data=playstore_df, ax=ax[1])

#Replacing null values in rating column with its median value
playstore_df['Rating'].fillna(value=median_rating,inplace=True)

playstore_df.isnull().sum()

"""##Handling Duplicates values and Manipulation Dataset"""

playstore_df[playstore_df['App'].duplicated()]

playstore_df[playstore_df['App'] == 'Box']

playstore_df.drop_duplicates(subset='App',inplace=True)

"""##Handling Duplicates and Manipulating Dataset"""

playstore_df.shape

"""1.)  Changing the datatype of the Last Updated column from string to datetime."""

# Pandas to_datetime() function applied to the values in the last updated column helps to convert string Date time into Python Date time object.
playstore_df['Last Updated'] = pd.to_datetime(playstore_df['Last Updated'])

playstore_df.head(5)

"""2.) Change the price column from string to int float type"""

playstore_df['Price'].value_counts()

def to_integer(n):
  if '$' in n:
    return float(n[1:])
  else:
    return float(n)

playstore_df['Price'] = playstore_df['Price'].apply(lambda x:to_integer(x))

"""4.)Converting the values in the Installs column from string datatype to integer datatype."""

#checking the content of Installs column
playstore_df['Installs'].value_counts()

def convert_integer(val):
  if '+' and ',' in val:
    new=int(val[:-1].replace(',',''))
    return new
  elif '+' in val:
    new1= int(val[:-1])
    return new1
  else:
    return int(val)

playstore_df['Installs'] = playstore_df['Installs'].apply(lambda x:convert_integer(x))

playstore_df.head(2)

"""*   The Installs column contains integer values indicating the minimum number of app installs, with 0 for no installs and higher values representing increasing user counts (e.g., 1 for at least one install, 1,000,000 for at least a million installs).

*  The datatype of the Installs column has been successfully converted from string to integer

4.) Converting the values in the Size column to a same unit of measure(MB)
"""

playstore_df['Size'].value_counts()

## Defining a function to convert all the entries in KB to MB and then converting them to float datatype.
def convert_kb_to_mb(val):
  try:
    if 'M' in val:
      return float(val[:-1])
    elif 'k' in val:
      return round(float(val[:-1])/1024,4)
    else:
      return val
  except:
    return val

"""##Applying the kb_to_mb function to convert the values in the Size column to a single unit of measure (MB) and the datatype from string to float

"""

# The kb_to_mb funtion applied to the size column
playstore_df['Size'] = playstore_df['Size'].apply(lambda x:convert_kb_to_mb(x))

playstore_df.head(5)

playstore_df['Size'] = playstore_df['Size'].apply(lambda x: str(x).replace('Varies with device', 'NaN') if 'Varies with device' in str(x) else x)
playstore_df['Size'] = playstore_df['Size'].apply(lambda x: float(x))

# Finding max, min, mean, and median in the Size column excluding the 'Varies with device' values.
max_size=playstore_df[playstore_df['Size'] != 'Varies with device']['Size'].max()

min_size = playstore_df[playstore_df['Size'] != 'Varies with device']['Size'].min()

mean_size = round(playstore_df[playstore_df['Size'] != 'Varies with device']['Size'].mean(),4)

median_size = playstore_df[playstore_df['Size'] != 'Varies with device']['Size'].median()

[max_size, min_size, mean_size, median_size]

# Distplot
fig, ax = plt.subplots(2,1, figsize=(12,6))
sns.distplot(playstore_df[playstore_df['Size'] != 'Varies with device']['Size'], ax=ax[0])
sns.boxplot(x='Size',data=playstore_df, ax=ax[1])
plt.show()

"""##Converting the datatype of values in the Reviews column from string to int."""

playstore_df['Reviews'] = playstore_df['Reviews'].astype(int)
playstore_df.head(2)

playstore_df.describe()

"""##We have successfully converted the datatype of the values in the Reviews column from string to int.

##Data Exploration - Univariate & Bivariate Analysis

*  Pair plot is used to understand the best set of features to explain a relationship between two variables or to form the most separated clusters. It also helps to form some simple classification models by drawing some simple lines or make linear separation in our data-set.


* Plot a pairwise plot between all the quantitative variables to look for any evident patterns or relationships between the features
"""

import warnings
#sns.set(font_scale=1.5)
warnings.filterwarnings("ignore")

playstore_df.to_csv('Final Playstore.csv')

Rating = playstore_df['Rating']
Size = playstore_df['Size']
Installs = playstore_df['Installs']
Reviews = playstore_df['Reviews']
Type = playstore_df['Type']
Price = playstore_df['Price']

p = sns.pairplot(pd.DataFrame(list(zip(Rating, Size, np.log(Installs), np.log10(Reviews), Price, Type)),
                        columns=['Rating','Size', 'Installs', 'Reviews', 'Price','Type']), hue='Type')
p.fig.suptitle("Pairwise Plot - Rating, Size, Installs, Reviews, Price",x=0.5, y=1.0, fontsize=16)

"""##Findings
Most of the App are Free. Most of the Paid Apps have Rating around 4 As the number of installation increases the number of reviews of the particaular app also increases. Most of the Apps are light-weighted.

##Explore User _ Review _ Data
"""

## Reading the userreviews.csv file
file_path2 = '/content/User Reviews.csv'
ur_df=pd.read_csv(file_path2)
ur_df.head()

ur_df.info()

# Checking shape and column in dataframe
print(ur_df.columns)
rows=ur_df.shape[0]
columns=ur_df.shape[1]
print(f"the no of rows is {rows} and no of columns is {columns}")

data=pd.DataFrame({'data_types':ur_df.dtypes,
                   'null_values':ur_df.isnull().sum(),
                   'not null values':ur_df.count(),
                    'unique_count':ur_df.nunique()
                    })

data

"""##Findings


*  Translated_Review has 26868 null values which contributes 41.79% of the data.
*  Sentiment has 26863 null values which contributes 41.78% of the data.
* Sentiment_Polarity has 26863 null values which contributes 41.78% of the data.
* Sentiment_Subjectivity has 26863 null values which contributes 41.78% of the data.

##cleaning the user review DataFrame


##Handling errors and  the Null Values in the user reviews
"""

## Finding the total no of NaN values in each column.
ur_df.isnull().sum()

# checking the NaN values in the translated review column
ur_df[ur_df['Translated_Review'].isnull()]

"""##There are a total of 26868 rows containing NaN values in the Translated_Review column.

We can say that the apps which do not have a review (NaN value insted) tend to have NaN values in the columns Sentiment, Sentiment_Polarity, and Sentiment_Subjectivity in the majority of the cases.

##Lets check if they are any exceptions
"""

# The rows corresponding to the NaN values in the translated_review column, where the rest of the columns are non null.
ur_df[ur_df['Translated_Review'].isnull() & ur_df['Sentiment'].notna()]

"""##In the few exceptional cases where the values of remaining columns are non null for null values in the translated_Review column, there seems to be errors. This is because the Sentiment, sentiment ploarity and sentiment subjectivity of the review can be determined if and only if there is a corresponding review.

##Hence these values are wrong and can be deleted altogather.
"""

#Delete the rows that containing Nan values
ur_df = ur_df.dropna()
#The shape of updated df
ur_df.shape

##Inspecting the sentiment column
ur_df['Sentiment'].value_counts()

"""##Data Visualization on play store data:


##We have sucessfully cleaned the dirty data. Now we can perform some data visualization and come up with insights on the given datasets.

1.)Correlation Heatmap
"""

# Assuming playstore_df is your DataFrame
# Select only the numeric columns
numeric_df=playstore_df.select_dtypes(include=['float64','int64'])

##calculation of correlation matrix
correlation_matrix= numeric_df.corr()

correlation_matrix

#heat_map for playstore data
plt.figure(figsize=(10,6))
sns.heatmap(correlation_matrix.corr(),annot=True)
plt.title('Corelation Heatmap for Playstore Data')
plt.show()

"""* There is a strong positive correlation between the Reviews and Installs column. This is pretty much obvious. Higher the number of installs, higher is the user base, and higher are the total number of reviews dropped by the users.
* The Priceis slightly negatively correlated with the Rating, Reviews, and Installs. This means that as the prices of the app increases, the average rating, total number of reviews and Installs fall slightly.

* The Rating is slightly positively correlated with theInstalls and Reviews column. This indicates that as the the average user rating increases, the app installs and number of reviews also increase.

2.) What is the ratio of number of Paid apps and Free apps?
"""

data = playstore_df['Type'].value_counts()
labels = ['Free', 'Paid']

# create pie chart
plt.figure(figsize=(10,6))
colors = ["#00EE76","#7B8895"]
explode=(0.01,0.1)
plt.pie(data, labels = labels, colors = colors, autopct='%.2f%%',explode=explode,textprops={'fontsize': 15})
plt.title('Distribution of Paid and Free apps',size=15,loc='center')
plt.legend()

"""##Findings
  
  * From the above graph we can see that 92% of apps in google play store are free and 8% are paid.

3.) Which category of Apps from the Content Rating column are found more on playstore?
"""

#content rating of apps
data = playstore_df['Content Rating'].value_counts()
labels=['Everyone', 'Teen', 'Everyone 10+', 'Mature 17+','Adults only 18+', 'Unrated']

## craete a pie chart
plt.figure(figsize=(13,10))
colors=['#DFDC1C', 'r', 'c', 'g', 'm', 'k']
explode=(0,0.1,0.1,0.1,0.0,1.3)
plt.pie(data, labels = labels,colors = colors ,autopct='%0.2f%%',explode=explode,textprops={'fontsize':15})
plt.title('Content Rating',size=20,loc='center')
plt.legend()

"""##A majority of the apps (82%) in the play store are can be used by everyone.The remaining apps have various age restrictions to use it.

## Top categories on playstore data
"""

playstore_df.groupby('Category')['App'].count().sort_values(ascending=False)

x = playstore_df['Category'].value_counts()
y = playstore_df['Category'].value_counts().index

#Number of apps belonging to each category in the playstore
plt.figure(figsize=(10,6))
plt.xlabel('Number of Apps', size=15)
plt.ylabel('App Categories', size=15)
graph = sns.barplot(y = x, x = y, palette= "tab10")
graph.set_title("Top categories on Playstore", fontsize = 25)
graph.set_xticklabels(graph.get_xticklabels(), rotation= 45, horizontalalignment='right',);

"""##Findings


*  So there are all total 33 categories in the dataset From the above output we
   can come to a conclusion that in playstore most of the apps are underFAMILY & GAME category and least are of EVENTS & BEAUTY Category.
  


"""

# Percentage of apps belonging to each category in the playstore
plt.figure(figsize=(20,15))
plt.pie(playstore_df.Category.value_counts(), labels=playstore_df.Category.value_counts().index, autopct='%1.2f%%')
my_circle = plt.Circle( (0,0), 0.50, color='white')
p=plt.gcf()
p.gca().add_artist(my_circle)
plt.title('% of apps share in each Category', fontsize = 25)
plt.show()

"""##Data Visualization on User Reviews:

1). Percentage of Review Sentiments
"""

ur_df.columns

data=ur_df['Sentiment'].value_counts()
labels=['positive','negative','Neutral']
plt.figure(figsize=(10,6))
colors=['red','aqua','magenta']
plt.title('Percentage of Review Sentiments')
plt.pie(data,labels=labels,colors=colors,autopct='%.2f%%')
plt.show()

"""##Findings

*  Positive reviews are 64.30%
*  Negative reviews are 22.80%
*  Neutral reviews are 12.90%

2.)App with highest number of positive reviews
"""

positive_ur_df=ur_df[ur_df['Sentiment']=='Positive']
positive_ur_df

positive_ur_df.groupby('App')['Sentiment'].value_counts().nlargest(8).plot.barh(figsize=(10,6),color='#3094e6').invert_yaxis()
plt.title("Top 10 positive review apps")
plt.xlabel('Total number of positive reviews')
plt.legend()

"""3.) App with Highest negative reviews"""

negative_ur_df=ur_df[ur_df['Sentiment'] == 'Negative']

negative_ur_df.groupby('App')['Sentiment'].value_counts().nlargest(10).plot.barh(figsize=(15,8),color='#d6203e').invert_yaxis()
plt.title("Top 10 negative review apps")
plt.xlabel('Total number of negative reviews')
plt.legend()

"""##How content rating affect over the app


1.)Paid App content rating
"""

# Creating a df containing only paid apps
paid_df=playstore_df[playstore_df['Type']=='Paid']

paid_df['Content Rating'].value_counts().plot.bar(figsize=(10,6),color='seagreen')
plt.legend()

#number of apps that can be installed at a particular price
paid_df.groupby('Price')['App'].count().sort_values(ascending= False).plot.bar(figsize = (25,6), color = '#20a6d6')#

"""The paid apps charge the users a certain amount to download and install the app. This amount varies from one app to another.

There are a lot of apps that charge a small amount whereas some apps charge a larger amount. In this case the price to download an app varies from USD 0.99 to USD 400.

In order to select the top paid apps, it won't be fair to look just into the numer of installs. This is because the apps that charge a lower installation fee will be installed by more number of people in general.

Here a better way to determine the top apps in the paid category is by finding the revenue it generated through app installs.

This is given by:

Revenue generated through installs = (Number of installs)x(Price to install the app)

##Lets define a new column Revenue in paid_df which gives the revenue generated by the app through installs alone.
"""

# Creatng a new column 'Revenue' in paid_df
paid_df['Revenue'] = paid_df['Installs']*paid_df['Price']
paid_df.head()

# Top app in the paid category
paid_df[paid_df['Revenue'] == paid_df['Revenue'].max()]

# Top 10 paid apps in the play store
top10paid_apps=paid_df.nlargest(10, 'Revenue', keep='first')
top10paid_apps['App']

# Categories in which the top 10 paid apps belong to
top10paid_apps['Category'].value_counts().plot.bar(figsize=(10,6), color= ["#13d152", "red", "#f09307", "blue", "#f0e807"])
plt.xlabel('Category',size=8)
plt.ylabel('Number of apps',size=8)
plt.title('Categories in which the top 10 paid apps belong', size=15)
plt.xticks(rotation=0)
plt.legend()

# Top paid apps according to the revenue generated through installs alone
top10paid_apps.groupby('App')['Revenue'].mean().sort_values(ascending= True).plot.barh(figsize=(16,10), color='brown')
plt.xlabel('Revenue Generated (USD)', size=15)
plt.title('Top apps based on revenue generated through installation fee', size=20)
plt.legend()

"""##Distribution of App update over the Year"""

# Creating a df for only free apps
free_df = playstore_df[playstore_df['Type'] == 'Free']

paid_df["Update year"] = paid_df["Last Updated"].apply(lambda x: x.strftime('%Y')).astype('int64')
free_df["Update year"] = free_df["Last Updated"].apply(lambda x: x.strftime('%Y')).astype('int64')

paid_df.groupby("Update year")["App"].count().plot.line(marker='o')
free_df.groupby('Update year')['App'].count().plot.line(marker='o')

"""n the above plot, we plotted the apps updated or added over the years comparing Free vs. Paid, by observing this plot we can conclude that before 2011 there were no paid apps, but with the years passing free apps has been added more in comparison to paid apps, By comparing the apps updated or added in the year 2011 and 2018 free apps are increases from 80% to 96% and paid apps are goes from 20% to 4%. So we can conclude that most of the people are after free apps

##Distribution of Paid and Free app updated over the Month
"""

paid_df["Update month"] = paid_df["Last Updated"].apply(lambda x: x.strftime('%m')).astype('int64')
free_df["Update month"] = free_df["Last Updated"].apply(lambda x: x.strftime('%m')).astype('int64')

paid_df.groupby("Update month")["App"].count().plot.bar(figsize=(10,8), color= "blue")
plt.title("Paid Apps update over the month", size=20)
plt.legend()

"""##Most of the paid apps too updates in the month of July same as free apps."""

free_df.groupby("Update month")["App"].count().plot.bar(figsize=(10,6), color='seagreen')
plt.title("Free Apps update over the month", size=15)
plt.legend()

"""##In this data almost 50% apps are added or updated on the month of July, 25% of apps are updated or added on the month of August and rest of 25% remaining months

##Playstore App Analysis Report

In our analysis of Play Store applications, we aimed to provide AlmaBetter with actionable insights to enhance their app launches.

Intial Phase

*   Problem Statements & Data Cleaning: We began by clearly defining the problems and meticulously cleaning the data to ensure high-quality analysis.

Key Recommendations:

*   Target Underexplored Categories: Focus on developing apps in less saturated categories like events and beauty.
*   Emphasize Free Apps: With the majority of apps being free, AlmaBetter should prioritize free app offerings.
* Content for Everyone: Apps catering to all age groups tend to get more installs.

* Regular Updates: Frequent updates can attract and retain more users.

* User Sentiment & Needs: Pay close attention to user feedback and evolving needs to enhance app features and user satisfaction.

##Analysis Highlights:


* Free Apps: ~92% of apps are free.
* No Age Restrictions: ~82% of apps are available for all age groups.
* Competitive Category: The most competitive category is Family.
* Highest Average Installs: Games category leads with the highest average installs.
* Top Rated Apps: ~80% of apps are top-rated.
* Top Categories by App Count: Family (1906 apps), Game (926 apps), Tools (829 apps).
* Top Genres: Tools, Entertainment, Education, Business, Medical.
* App Size Insights:
   * 8783 apps are under 50 MB.
   * 7749 apps have ratings above 4.0.
   * Median app size is 12 MB.
   * Apps with variable sizes have the highest average installs.
   * Apps over 90 MB receive the most user reviews.



   ##Install Statistics:

* 20 free apps have over a billion installs.
* Minecraft is the only paid app with over 10 million installs, generating the
  most revenue from installation fees.
* Finance category has the highest average installation fee for paid apps.


##User Reviews:
 * Helix Jump has the highest number of positive reviews
 * Angry Birds Classic has the highest number of negative reviews.

##Sentiment Analysis:
* Positive: 64%
* Negative: 22%
* Neutral: 13%
##These insights provide a comprehensive understanding of the Play Store landscape, aiding AlmaBetter in making informed decisions for their app development and marketing strategies.

##Challenges & Future Work

Challenges:

1. Data Cleaning: One of our primary challenges was the extensive data cleaning
    required.
2. Missing Reviews: We encountered 13.60% NaN values in reviews. Even after
   merging dataframes, these missing values could not be inferred and were subsequently dropped.
3.Limited Merged Data: The merged dataframe of Play Store and user reviews     contained only 816 common apps, representing just 10% of the cleaned data. More valuable insights could have been derived if we had 70%-80% of the data in the merged dataframes.
4. High NaN Values in User Reviews: User reviews had 42% NaN values. If these
 values were available, they could have provided a better understanding of category-wise sentiments and potentially helped fill the 13.60% NaN values in the Reviews column.

##Future Work:
1. Version Analysis: Exploring the impact of current and Android versions on app performance to provide more detailed analysis for developers.
2. Correlation Studies: Investigate the correlation between app size, Android version, and the number of installs.
3. Machine Learning Models: Develop machine learning models to derive deeper insights and improve interpretability. This future work could significantly enhance our analysis capabilities.
"""